{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# preprocessing imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions we implemented\n",
    "from custom_functions import init_embeddings_map, get_embed_and_pad_func, get_embed_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 50\n",
    "embedding_map = init_embeddings_map(\"glove.6B.\" + str(emb_size) + \"d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"data/unembedded_grouped_cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_size: 2928\n",
      "test_users_size: 14\n"
     ]
    }
   ],
   "source": [
    "# Train/test split for our model is unique, we need to hold out a\n",
    "# set of users and movies so that our network never learns those \n",
    "test_size = 0.005\n",
    "\n",
    "# get test_size percentage of users\n",
    "unique_users = raw_data.loc[:, \"reviewerID\"].unique()\n",
    "users_size = len(unique_users)\n",
    "print('users_size:', users_size)\n",
    "np.random.seed(2019)\n",
    "test_idx = np.random.choice(users_size,\n",
    "                              size=int(users_size * test_size),\n",
    "                              replace=False)\n",
    "\n",
    "# get test users\n",
    "test_users = unique_users[test_idx]\n",
    "print('test_users_size:', len(test_users))\n",
    "\n",
    "# everyone else is a training user\n",
    "train_users = np.delete(unique_users, test_idx)\n",
    "\n",
    "test = raw_data[raw_data[\"reviewerID\"].isin(test_users)]\n",
    "train = raw_data[raw_data[\"reviewerID\"].isin(train_users)]\n",
    "\n",
    "unique_test_movies = test[\"asin\"].unique()\n",
    "\n",
    "# drop the movies that also appear in our test set. In order to be\n",
    "# a true train/test split, we are forced to discard some data entirely\n",
    "train = train.where(np.logical_not(train[\"asin\"].isin(unique_test_movies))).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_seq_sizes = raw_data.loc[:, \"userReviews\"].apply(lambda x: x.split()).apply(len)\n",
    "item_seq_sizes = raw_data.loc[:, \"movieReviews\"].apply(lambda x: x.split()).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ptile = 40\n",
    "i_ptile = 15\n",
    "u_seq_len = int(np.percentile(user_seq_sizes, u_ptile))\n",
    "i_seq_len = int(np.percentile(item_seq_sizes, i_ptile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_fn = get_embed_and_pad_func(i_seq_len, u_seq_len, np.array([0.0] * emb_size), embedding_map)\n",
    "\n",
    "train_embedded = train.apply(embedding_fn, axis=1)\n",
    "test_embedded = test.apply(embedding_fn, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aspects 超参数设置 与 Embedding映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 50)\n"
     ]
    }
   ],
   "source": [
    "# aspects = ['price', 'quality', 'battery', 'oil', 'car', 'tire', 'paint', 'light', 'engine']\n",
    "aspects = ['price', 'quality', 'oil', 'paint', 'engine']\n",
    "embed_aspects = get_embed_aspects(aspects, embedding_map)\n",
    "print(embed_aspects.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "粘贴来的one_step_of_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define part of the attention layer gloablly so as to\n",
    "# share the same layers for each attention step.\n",
    "def softmax(x):\n",
    "    return K.softmax(x, axis=1)\n",
    "\n",
    "at_repeat = RepeatVector(Tx)\n",
    "at_concatenate = Concatenate(axis=-1)\n",
    "at_dense1 = Dense(8, activation=\"tanh\")\n",
    "at_dense2 = Dense(1, activation=\"relu\")\n",
    "at_softmax = Activation(softmax, name='attention_weights')\n",
    "at_dot = Dot(axes=1)\n",
    "\n",
    "def one_step_of_attention(h_prev, a):\n",
    "    \"\"\"\n",
    "    Get the context.\n",
    "    \n",
    "    Input:\n",
    "    h_prev - Previous hidden state of a RNN layer (m, n_h)\n",
    "    a - Input data, possibly processed (m, Tx, n_a)\n",
    "    \n",
    "    Output:\n",
    "    context - Current context (m, Tx, n_a)\n",
    "    \"\"\"\n",
    "    # Repeat vector to match a's dimensions\n",
    "    h_repeat = at_repeat(h_prev)\n",
    "    # Calculate attention weights\n",
    "    i = at_concatenate([a, h_repeat])\n",
    "    i = at_dense1(i)\n",
    "    i = at_dense2(i)\n",
    "    attention = at_softmax(i)\n",
    "    # Calculate the context\n",
    "    context = at_dot([attention, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling imports\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input, Dense, Permute, Reshape, RepeatVector, Activation, Lambda\n",
    "from keras.activations import tanh, softmax\n",
    "from keras.layers.merge import Add, Dot, Concatenate, Multiply\n",
    "from MyLayer import WeightedAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel():\n",
    "    def __init__(self, embedding_size, hidden_size, rnn_hidden_size, u_seq_len, m_seq_len, n_aspects, filters=2, kernel_size=8,\n",
    "                 strides=6):\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_aspects = n_aspects\n",
    "        self.embed_aspects = Input(shape=(self.n_aspects, self.embedding_size))\n",
    "        self.inputU, self.towerU = self.create_deepconn_tower(u_seq_len)\n",
    "        self.inputM, self.towerM = self.create_deepconn_tower(m_seq_len)\n",
    "        # self.joined = Concatenate()([self.towerU, self.towerM])\n",
    "        # self.outNeuron = Dense(1)(self.joined)\n",
    "    \n",
    "    def aspect_attention_block(self, lstm_inputs, embed_aspect_repeat, LSTM_1, Dense_1, Dense_2, Dense_3, WeightedAdd_1, Dense_4):\n",
    "        lstm_out = LSTM_1(lstm_inputs)\n",
    "        wh = Dense_1(lstm_out)\n",
    "        wv = Dense_2(embed_aspect_repeat)\n",
    "        m = Concatenate(axis=-1)([wh, wv])\n",
    "        m = Activation(tanh)(m)\n",
    "        a_probs = Dense_3(m)\n",
    "        output_attention_mul = Dot(axes=1)([lstm_out, a_probs])\n",
    "        # name='attention_mul'\n",
    "        output_attention_mul = Reshape((self.rnn_hidden_size, ))(output_attention_mul)\n",
    "        aspect_rating = Dense_4(output_attention_mul)\n",
    "        \n",
    "        return aspect_rating\n",
    "        \n",
    "    def create_deepconn_tower(self, max_seq_len):\n",
    "        input_layer = Input(shape=(max_seq_len, self.embedding_size))\n",
    "        # 用于变量的动态命名\n",
    "        createVar = locals()\n",
    "        \n",
    "        # 不同aspect间的参数共享\n",
    "        LSTM_1 = LSTM(self.rnn_hidden_size, activation=\"tanh\", return_sequences=True)\n",
    "        Dense_1 = Dense(self.rnn_hidden_size, kernel_initializer='glorot_normal')\n",
    "        Dense_2 = Dense(self.embedding_size, kernel_initializer='glorot_normal')\n",
    "        Dense_3 = Dense(1, activation=\"softmax\")\n",
    "        # name='attention_vec'\n",
    "        WeightedAdd_1 = WeightedAdd(1)\n",
    "        Dense_4 = Dense(1, activation=\"softmax\")\n",
    "        \n",
    "        for n in range(self.n_aspects):\n",
    "            one_embed_aspects = Lambda(lambda x: x[:, n])(self.embed_aspects)\n",
    "            \n",
    "            embed_aspect_repeat = RepeatVector(max_seq_len)(one_embed_aspects)\n",
    "            # 问题出在[:,:,]，要用Lambda层\n",
    "            lstm_inputs = Concatenate(axis=-1)([input_layer, embed_aspect_repeat])\n",
    "            createVar['tower'+str(n)] = self.aspect_attention_block(lstm_inputs, embed_aspect_repeat, LSTM_1, Dense_1, Dense_2, Dense_3, WeightedAdd_1, Dense_4)\n",
    "\n",
    "        for n in range(self.n_aspects-1):\n",
    "           createVar['tower0'] = Concatenate(axis=-1)([createVar['tower0'], createVar['tower'+str(n+1)]])\n",
    "        tower = createVar['tower0']\n",
    "        print(\"user/item aspect feature:\", tower.shape)\n",
    "        \n",
    "        return input_layer, tower\n",
    "\n",
    "    def create_deepconn_dp(self):\n",
    "        dotproduct = Dot(axes=1)([self.towerU, self.towerM])\n",
    "        # output = Add()([self.outNeuron, dotproduct])\n",
    "        show = Concatenate(axis=-1)([self.towerU, self.towerM])\n",
    "        output = Dense(1, use_bias=True)(dotproduct)\n",
    "        self.model = Model(inputs=[self.embed_aspects, self.inputU, self.inputM], outputs=[output])\n",
    "        self.model.compile(optimizer='Adam', loss='mse')\n",
    "        \n",
    "    def train(self, train_data, embed_aspects, batch_size, epochs=3500):\n",
    "        tensorboard = TensorBoard(log_dir=\"tf_logs/{}\".format(time()))\n",
    "        self.create_deepconn_dp()\n",
    "        print(self.model.summary())\n",
    "        \n",
    "        user_reviews = np.array(list(train_data.loc[:, \"userReviews\"]))\n",
    "        movie_reviews = np.array(list(train_data.loc[:, \"movieReviews\"]))\n",
    "        \n",
    "        # 将aspects扩充至训练集的大小\n",
    "        embed_aspects = np.expand_dims(embed_aspects, axis=0)\n",
    "        embed_aspects = np.repeat(embed_aspects, user_reviews.shape[0], axis=0)\n",
    "        \n",
    "        self.train_inputs = [embed_aspects, user_reviews, movie_reviews]\n",
    "        self.train_outputs = train_data.loc[:, \"overall\"]\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, mode='auto')\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min')\n",
    "        self.history = self.model.fit(self.train_inputs,\n",
    "                                      self.train_outputs,\n",
    "                                      callbacks=[tensorboard, reduce_lr, early_stopping],\n",
    "                                      validation_split=0.05,\n",
    "                                      batch_size=batch_size,\n",
    "                                      epochs=epochs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user/item aspect feature: (?, 5)\n",
      "user/item aspect feature: (?, 5)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 5, 50)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 50)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 50)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 50)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 318, 50)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 318, 50)      0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 318, 50)      0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 50)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 329, 50)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_6 (RepeatVector)  (None, 329, 50)      0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_7 (RepeatVector)  (None, 329, 50)      0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 50)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 318, 100)     0           input_2[0][0]                    \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 318, 100)     0           input_2[0][0]                    \n",
      "                                                                 repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_3 (RepeatVector)  (None, 318, 50)      0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 50)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 329, 100)     0           input_3[0][0]                    \n",
      "                                                                 repeat_vector_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 329, 100)     0           input_3[0][0]                    \n",
      "                                                                 repeat_vector_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_8 (RepeatVector)  (None, 329, 50)      0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 50)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 318, 64)      42240       concatenate_1[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 318, 100)     0           input_2[0][0]                    \n",
      "                                                                 repeat_vector_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_4 (RepeatVector)  (None, 318, 50)      0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 50)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 329, 64)      42240       concatenate_15[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "                                                                 concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 329, 100)     0           input_3[0][0]                    \n",
      "                                                                 repeat_vector_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_9 (RepeatVector)  (None, 329, 50)      0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 50)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 318, 64)      4160        lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 318, 50)      2550        repeat_vector_1[0][0]            \n",
      "                                                                 repeat_vector_2[0][0]            \n",
      "                                                                 repeat_vector_3[0][0]            \n",
      "                                                                 repeat_vector_4[0][0]            \n",
      "                                                                 repeat_vector_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 318, 100)     0           input_2[0][0]                    \n",
      "                                                                 repeat_vector_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_5 (RepeatVector)  (None, 318, 50)      0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 329, 64)      4160        lstm_2[0][0]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 lstm_2[2][0]                     \n",
      "                                                                 lstm_2[3][0]                     \n",
      "                                                                 lstm_2[4][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 329, 50)      2550        repeat_vector_6[0][0]            \n",
      "                                                                 repeat_vector_7[0][0]            \n",
      "                                                                 repeat_vector_8[0][0]            \n",
      "                                                                 repeat_vector_9[0][0]            \n",
      "                                                                 repeat_vector_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 329, 100)     0           input_3[0][0]                    \n",
      "                                                                 repeat_vector_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_10 (RepeatVector) (None, 329, 50)      0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 318, 114)     0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 318, 114)     0           dense_1[1][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 318, 100)     0           input_2[0][0]                    \n",
      "                                                                 repeat_vector_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 329, 114)     0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 329, 114)     0           dense_5[1][0]                    \n",
      "                                                                 dense_6[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 329, 100)     0           input_3[0][0]                    \n",
      "                                                                 repeat_vector_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 318, 114)     0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 318, 114)     0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 318, 114)     0           dense_1[2][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 329, 114)     0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 329, 114)     0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 329, 114)     0           dense_5[2][0]                    \n",
      "                                                                 dense_6[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 318, 1)       115         activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 318, 114)     0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 318, 114)     0           dense_1[3][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 329, 1)       115         activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 329, 114)     0           concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 329, 114)     0           dense_5[3][0]                    \n",
      "                                                                 dense_6[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 64, 1)        0           lstm_1[0][0]                     \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 64, 1)        0           lstm_1[1][0]                     \n",
      "                                                                 dense_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 318, 114)     0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 318, 114)     0           dense_1[4][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_6 (Dot)                     (None, 64, 1)        0           lstm_2[0][0]                     \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_7 (Dot)                     (None, 64, 1)        0           lstm_2[1][0]                     \n",
      "                                                                 dense_7[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 329, 114)     0           concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 329, 114)     0           dense_5[4][0]                    \n",
      "                                                                 dense_6[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 64)           0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 64)           0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 64, 1)        0           lstm_1[2][0]                     \n",
      "                                                                 dense_3[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 318, 114)     0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 64)           0           dot_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 64)           0           dot_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_8 (Dot)                     (None, 64, 1)        0           lstm_2[2][0]                     \n",
      "                                                                 dense_7[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 329, 114)     0           concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            65          reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 64)           0           dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 64, 1)        0           lstm_1[3][0]                     \n",
      "                                                                 dense_3[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            65          reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 64)           0           dot_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_9 (Dot)                     (None, 64, 1)        0           lstm_2[3][0]                     \n",
      "                                                                 dense_7[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 2)            0           dense_4[0][0]                    \n",
      "                                                                 dense_4[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 64)           0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_5 (Dot)                     (None, 64, 1)        0           lstm_1[4][0]                     \n",
      "                                                                 dense_3[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 2)            0           dense_8[0][0]                    \n",
      "                                                                 dense_8[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 64)           0           dot_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_10 (Dot)                    (None, 64, 1)        0           lstm_2[4][0]                     \n",
      "                                                                 dense_7[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 3)            0           concatenate_11[0][0]             \n",
      "                                                                 dense_4[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 64)           0           dot_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 3)            0           concatenate_25[0][0]             \n",
      "                                                                 dense_8[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 64)           0           dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 4)            0           concatenate_12[0][0]             \n",
      "                                                                 dense_4[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 4)            0           concatenate_26[0][0]             \n",
      "                                                                 dense_8[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 5)            0           concatenate_13[0][0]             \n",
      "                                                                 dense_4[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 5)            0           concatenate_27[0][0]             \n",
      "                                                                 dense_8[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_11 (Dot)                    (None, 1)            0           concatenate_14[0][0]             \n",
      "                                                                 concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            2           dot_11[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 98,262\n",
      "Trainable params: 98,262\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 17081 samples, validate on 900 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17081/17081 [==============================] - 1298s 76ms/step - loss: 112.7458 - val_loss: 81.1008\n",
      "Epoch 2/20\n",
      "17081/17081 [==============================] - 1298s 76ms/step - loss: 61.3940 - val_loss: 41.4444\n",
      "Epoch 3/20\n",
      "17081/17081 [==============================] - 1339s 78ms/step - loss: 30.0917 - val_loss: 18.6047\n",
      "Epoch 4/20\n",
      "17081/17081 [==============================] - 1342s 79ms/step - loss: 12.9135 - val_loss: 7.1407\n",
      "Epoch 5/20\n",
      "17081/17081 [==============================] - 1354s 79ms/step - loss: 4.8620 - val_loss: 2.4837\n",
      "Epoch 6/20\n",
      "17081/17081 [==============================] - 1464s 86ms/step - loss: 1.8609 - val_loss: 1.1162\n",
      "Epoch 7/20\n",
      "17081/17081 [==============================] - 1455s 85ms/step - loss: 1.0535 - val_loss: 0.8854\n",
      "Epoch 8/20\n",
      "17081/17081 [==============================] - 1443s 85ms/step - loss: 0.9149 - val_loss: 0.8812\n",
      "Epoch 9/20\n",
      "17081/17081 [==============================] - 1433s 84ms/step - loss: 0.9012 - val_loss: 0.8882\n",
      "Epoch 10/20\n",
      "17081/17081 [==============================] - 1420s 83ms/step - loss: 0.9005 - val_loss: 0.8888\n",
      "Epoch 11/20\n",
      "17081/17081 [==============================] - 1402s 82ms/step - loss: 0.9005 - val_loss: 0.8881\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 64\n",
    "rnn_hidden_size = 64\n",
    "n_aspects = len(aspects)\n",
    "mymodel = MyModel(emb_size, hidden_size, rnn_hidden_size, u_seq_len, i_seq_len, n_aspects)\n",
    "\n",
    "batch_size = 32\n",
    "mymodel.train(train_embedded, embed_aspects, batch_size, epochs=20)\n",
    "\n",
    "mymodel.model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 2.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 2.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]]\n",
      "[[ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]\n",
      " [ 4.45679092]]\n",
      "MSE: 0.931774007549\n"
     ]
    }
   ],
   "source": [
    "user_reviews = np.array(list(test_embedded.loc[:, \"userReviews\"]))\n",
    "movie_reviews = np.array(list(test_embedded.loc[:, \"movieReviews\"]))\n",
    "\n",
    "test_embed_aspects = np.expand_dims(embed_aspects, axis=0)\n",
    "test_embed_aspects = np.repeat(test_embed_aspects, user_reviews.shape[0], axis=0)\n",
    "\n",
    "test_inputs = [test_embed_aspects, user_reviews, movie_reviews]\n",
    "\n",
    "dat = pd.DataFrame(test_inputs)\n",
    "dat.to_csv(\"data/test_data.csv\")\n",
    "\n",
    "true_rating = np.array(list(test_embedded.loc[:, \"overall\"])).reshape((-1, 1))\n",
    "print(true_rating)\n",
    "\n",
    "predictions = mymodel.model.predict(test_inputs)\n",
    "print(predictions)\n",
    "\n",
    "error = np.square(predictions - true_rating)\n",
    "\n",
    "print(\"MSE:\", np.average(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取某一层的输出或参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取某一层的输出\n",
    "def get_layer_output(mymodel, layer_name, input_data):\n",
    "    layer_model = Model(inputs=mymodel.model.input, output=mymodel.model.get_layer(layer_name).output)\n",
    "    # predict 默认batch size是32\n",
    "    layer_out = layer_model.predict(input_data)\n",
    "    return layer_out\n",
    "\n",
    "# 获取某一层的权重和偏置\n",
    "def get_layer_parameter(mymodel, layer_name):\n",
    "    weights, bias = mymodel.model.get_layer(layer_name).get_weights()\n",
    "    return weights,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"co...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "layer_out = get_layer_output(mymodel, 'concatenate_28', test_inputs)\n",
    "print(layer_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
